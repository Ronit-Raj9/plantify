{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXlCWzuOHgi4"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnPVyXPwHMtT",
        "outputId": "4e1b6bb0-554b-49b3-87f7-41713fe6fbe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Notebook last run (end-to-end): <class 'datetime.datetime'>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.10.1\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime }\")\n",
        "# # Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dbeyN5eTjb_l"
      },
      "outputs": [],
      "source": [
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "\n",
        "  Args:\n",
        "    dir_path (str): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N0XyTCPvopku"
      },
      "outputs": [],
      "source": [
        "walk_through_dir(\"/content/plant_dataset.rar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtJeEsSZyVZw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EqNwQnYKj2Z0"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip_data(filename, extract_to=\".\"):\n",
        "    \"\"\"\n",
        "    Unzips a file into the specified directory.\n",
        "\n",
        "    Args:\n",
        "        filename (str): The filepath of the ZIP file to be unzipped.\n",
        "        extract_to (str): The directory where the contents will be extracted.\n",
        "                          Defaults to the current directory.\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eTM5HXyU1uYF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Example usage:\n",
        "# zip_file = \"plant_dataset.zip\"\n",
        "# unzip_data(zip_file, \"extracted_data\")  # Extracts to the \"extracted_data\" directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4SZxcdyHMtU",
        "outputId": "58452b4e-e700-4631-ecb3-74a88ad4f627"
      },
      "outputs": [],
      "source": [
        "#from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir\n",
        "walk_through_dir(\"/content/extracted_data/plant_dataset\")\n",
        "# Create training and test directories\n",
        "train_dir = \"/content/extracted_data/plant_dataset/train\"\n",
        "test_dir = \"/content/extracted_data/plant_dataset/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdgTvBXCHMtU",
        "outputId": "034bbc07-3d2b-450f-a6f1-f23ebd81d02f"
      },
      "outputs": [
        {
          "ename": "NotFoundError",
          "evalue": "Could not find directory /content/extracted_data/plant_dataset/train",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m IMG_SIZE \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m train_data_leaves \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                                            \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                                            \u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m test_data_leaves \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(directory\u001b[38;5;241m=\u001b[39mtest_dir,\n\u001b[0;32m      8\u001b[0m                                                                            image_size\u001b[38;5;241m=\u001b[39mIMG_SIZE,\n\u001b[0;32m      9\u001b[0m                                                                            label_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m train_data_leaves\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\image_dataset.py:207\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 207\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\dataset_utils.py:524\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    523\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 524\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    526\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:766\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \n\u001b[0;32m    753\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[1;32m--> 766\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m    767\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    768\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    769\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    774\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str_any(filename)\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mGetChildren(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    776\u001b[0m ]\n",
            "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory /content/extracted_data/plant_dataset/train"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "IMG_SIZE = (224,224)\n",
        "train_data_leaves = tf.keras.preprocessing.image_dataset_from_directory(directory =  train_dir,\n",
        "                                                                            image_size = IMG_SIZE,\n",
        "                                                                            label_mode = \"categorical\",\n",
        "                                                                            batch_size = 32)\n",
        "test_data_leaves = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
        "                                                                           image_size=IMG_SIZE,\n",
        "                                                                           label_mode=\"categorical\")\n",
        "train_data_leaves\n",
        "train_data_leaves.class_names\n",
        "for images, labels in train_data_leaves.take(1):\n",
        "  print(images, labels)\n",
        "train_data_leaves.take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEy9dW1IHMtU",
        "outputId": "13d395db-b350-47ed-e1ad-b640d629b698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
            "24274472/24274472 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1. Create base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
        "\n",
        "# OLD\n",
        "# base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model (so the pre-learned patterns remain)\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYXv89cx2SnO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib3QLCh1g2In",
        "outputId": "c734b3bb-de94-4e5f-d212-b9e132d7e43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after base_model: (None, 7, 7, 1280)\n",
            "After GlobalAveragePooling2D(): (None, 1280)\n",
            "Saving TensorBoard log files to: transfer_learning/10_percent_feature_extract/20240319-175408\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 47s 2s/step - loss: 0.6177 - accuracy: 0.8174 - val_loss: 0.2372 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 30s 2s/step - loss: 0.1609 - accuracy: 0.9978 - val_loss: 0.0891 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 32s 2s/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 30s 2s/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 34s 2s/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3. Create inputs into the base model\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "\n",
        "# 4. If using ResNet50V2, add this to speed up convergence, remove for EfficientNetV2\n",
        "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
        "\n",
        "# 5. Pass the inputs to the base_model (note: using tf.keras.applications, EfficientNetV2 inputs don't have to be normalized)\n",
        "x = base_model(inputs)\n",
        "# Check data shape after passing it to base_model\n",
        "print(f\"Shape after base_model: {x.shape}\")\n",
        "\n",
        "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "print(f\"After GlobalAveragePooling2D(): {x.shape}\")\n",
        "\n",
        "# 7. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(3, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "# 8. Combine the inputs with the outputs into a model\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile the model\n",
        "model_0.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# 10. Fit the model (we use less steps for validation so it's faster)\n",
        "history = model_0.fit(train_data_leaves,\n",
        "                                 epochs=5,\n",
        "                                 steps_per_epoch=len(train_data_leaves),\n",
        "                                 validation_data=train_data_leaves,\n",
        "                                 # Go through less of the validation data so epochs are faster (we want faster experiments!)\n",
        "                                 validation_steps=int(0.25 * len(train_data_leaves)),\n",
        "                                 # Track our model's training logs for visualization later\n",
        "                                 callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_feature_extract\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dNXfDLa41sl"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_0)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kudkNeZ41BlE",
        "outputId": "295a29d9-8250-4504-f7c0-aa2e2b8594e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 5s 2s/step - loss: 0.0831 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.08309602737426758, 1.0]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_0.evaluate(test_data_leaves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: {\n",
            "    \"error\": \"Malformed request: POST /v1/models/plant_model/1:predict\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "# import requests\n",
        "# from PIL import Image\n",
        "\n",
        "# # Read the image file\n",
        "# image_path = \"D:\\\\CODDING\\\\GITHUB\\\\EES\\\\dataset\\\\mangodataset\\\\Gall Midge\\\\IMG_20211106_162102 (Custom).jpg\"\n",
        "# image = Image.open(image_path)\n",
        "\n",
        "# # Resize the image to the required dimensions\n",
        "# target_size = (224, 224)\n",
        "# resized_image = image.resize(target_size)\n",
        "\n",
        "# # Convert the image to a numpy array of floating-point numbers\n",
        "# image_array = np.array(resized_image, dtype=np.float32)\n",
        "\n",
        "# # Normalize the pixel values (optional)\n",
        "# image_array /= 255.0\n",
        "\n",
        "# # Add a batch dimension\n",
        "# input_data = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "# # Prepare the input data in the required format (e.g., JSON)\n",
        "# input_json = {\n",
        "#     \"instances\": input_data.tolist()\n",
        "# }\n",
        "\n",
        "# # URL for the TensorFlow Serving REST API\n",
        "# api_url = \"http://localhost:8601/v1/models/plant_model/1:predict\"\n",
        "\n",
        "# # Send the POST request to the TensorFlow Serving API\n",
        "# response = requests.post(api_url, json=input_json)\n",
        "\n",
        "# # Check if the request was successful\n",
        "# if response.status_code == 200:\n",
        "#     # Get the predictions\n",
        "#     predictions = response.json()\n",
        "\n",
        "#     # Print the predictions\n",
        "#     print(predictions)\n",
        "# else:\n",
        "#     print(\"Error:\", response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Path to the saved model directory\n",
        "model_path = r'D:\\CODDING\\GITHUB\\EES\\plantify\\saved_model\\1'\n",
        "\n",
        "# Load the model\n",
        "model = tf.keras.models.load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('D:\\CODDING\\GITHUB\\EES\\dataset\\guava dataset\\Guava Dataset (Original Image)\\Disease Free\\Disease Free (7).jpg', target_size = (224, 224))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.96581906, 0.01451117, 0.01966973]], dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'predictions': [[0.0546299294, 0.705981195, 0.239388928]]}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "# Read the image file\n",
        "image_path = \"D:\\CODDING\\GITHUB\\EES\\dataset\\guava dataset\\Guava Dataset (Original Image)\\Disease Free\\Disease Free (7).jpg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Resize the image to the required dimensions\n",
        "target_size = (224, 224)\n",
        "resized_image = image.resize(target_size)\n",
        "\n",
        "# Convert the image to a numpy array of floating-point numbers\n",
        "image_array = np.array(resized_image, dtype=np.float32)\n",
        "\n",
        "# Normalize the pixel values (optional)\n",
        "image_array /= 255.0\n",
        "\n",
        "# Add a batch dimension\n",
        "input_data = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "# Prepare the input data in the required format (e.g., JSON)\n",
        "input_json = {\n",
        "    \"instances\": input_data.tolist()\n",
        "}\n",
        "# http://localhost:8501/v1/models/plant_model/versions/1:predict\n",
        "# URL for the TensorFlow Serving REST API\n",
        "api_url = \"http://localhost:8501/v1/models/plant_model/versions/1:predict\"\n",
        "\n",
        "# Send the POST request to the TensorFlow Serving API\n",
        "response = requests.post(api_url, json=input_json)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Get the predictions\n",
        "    predictions = response.json()\n",
        "\n",
        "    # Print the predictions\n",
        "    print(predictions)\n",
        "else:\n",
        "    print(\"Error:\", response.text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4625901,
          "sourceId": 7881548,
          "sourceType": "datasetVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelInstanceId": 4603,
          "sourceId": 6120,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30664,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
